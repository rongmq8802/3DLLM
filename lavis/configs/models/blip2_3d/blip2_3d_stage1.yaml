model:
  arch: blip2_3d_stage1
  load_finetuned: False

  # pretrained: ""
  # finetuned: ""

  # point transformer encoder
  cloud_max_size: 10000
  drop_path_rate: 0
  use_grad_checkpoint: False
  freeze_cloud_encoder: True

  # vit 未来要删去, 目前是为了兼容性
  image_size: 224
  vit_precision: "fp16"
  freeze_vit: True
  pretrained: "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained.pth"
  finetuned: ""

  # Q-Former
  num_query_token: 32
  qformer_encoder_layer: 12