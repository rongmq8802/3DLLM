model:
  arch: llama_chinese
  load_finetuned: False
  load_pretrained: False      # 目前为了调试设为了False 实际使用时要设为True 而且要为下面的 pretrained 参数赋值
  pretrained: ""
  finetuned: ""
  
  # point transformer encoder
  cloud_max_size: 10000
  drop_path_rate: 0
  use_grad_checkpoint: False
  freeze_cloud_encoder: True


  # Q-Former
  num_query_token: 32
  qformer_encoder_layer: 12

  # Llama
  llama_model: "llama_chinese"        # 名字, 目前没有作用
  pretrained_llama_path: "/home/tdt/Llama/"           # 预训练的llama模型的保存路径, 注意是一个文件夹, 绝对路径
  max_txt_length: 100